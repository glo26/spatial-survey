% ===================================================================
% COMPREHENSIVE BIBLIOGRAPHY FOR SPATIAL AI SURVEY
% 100+ References Organized by Category
% ===================================================================

% -------------------------------------------------------------------
% SECTION 1: FOUNDATIONAL AGENTIC ARCHITECTURES
% -------------------------------------------------------------------

@article{yao2023react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2023}
}

@article{schick2023toolformer,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{accarino2022mrkl,
  title={MRKL Systems: A Modular, Neuro-Symbolic Architecture that Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  author={Karpas, Ehud and Abend, Omri and Berant, Jonathan and others},
  journal={arXiv preprint arXiv:2205.00445},
  year={2022}
}

@article{yao2023tree,
  title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@article{shinn2023reflexion,
  title={Reflexion: Language Agents with Verbal Reinforcement Learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{wang2024survey,
  title={A Survey on Large Language Model based Autonomous Agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  year={2024}
}

@article{huang2024understanding,
  title={Understanding the Planning of LLM Agents: A Survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@article{park2023generative,
  title={Generative Agents: Interactive Simulacra of Human Behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  journal={arXiv preprint arXiv:2304.03442},
  year={2023}
}

@article{lewis2020rag,
  title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Kuttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktaschel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

% -------------------------------------------------------------------
% SECTION 2: EMBODIED AI AND SPATIAL PLANNING
% -------------------------------------------------------------------

@article{wang2023voyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{driess2023palme,
  title={PaLM-E: An Embodied Multimodal Language Model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{ahn2022saycan,
  title={Do As I Can, Not As I Say: Grounding Language in Robotic Affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gober, Keerthana and Gopalakrishnan, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@article{brohan2023rt2,
  title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{liang2023code,
  title={Code as Policies: Language Model Programs for Embodied Control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  journal={arXiv preprint arXiv:2209.07753},
  year={2023}
}

@inproceedings{song2023llmplanner,
  title={LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3009},
  year={2023}
}

@article{lin2022vima,
  title={VIMA: General Robot Manipulation with Multimodal Prompts},
  author={Lin, Yunfan and Xie, Yuqi and Xiao, Chaowei and Anandkumar, Anima and Zhu, Yuke},
  journal={arXiv preprint arXiv:2210.03094},
  year={2022}
}

@inproceedings{anderson2018vln,
  title={Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and Sunderhauf, Niko and Reid, Ian and Gould, Stephen and van den Hengel, Anton},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3674--3683},
  year={2018}
}

@inproceedings{chen2019touchdown,
  title={Touchdown: Natural Language Navigation and Spatial Reasoning in Visual Street Environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12538--12547},
  year={2019}
}

@article{hong2020vlnbert,
  title={VLN-BERT: A Recurrent Vision-and-Language BERT for Navigation},
  author={Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
  journal={arXiv preprint arXiv:2011.13922},
  year={2020}
}

@inproceedings{savva2019habitat,
  title={Habitat: A Platform for Embodied AI Research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9339--9347},
  year={2019}
}

@article{gupta2019neuralslam,
  title={Cognitive Mapping and Planning for Visual Navigation},
  author={Gupta, Saurabh and Tolani, Varun and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
  journal={International Journal of Computer Vision},
  volume={128},
  number={5},
  pages={1311--1330},
  year={2019}
}

% -------------------------------------------------------------------
% SECTION 3: MULTIMODAL LARGE LANGUAGE MODELS
% -------------------------------------------------------------------

@article{liu2023llava,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@article{openai2023gpt4v,
  title={GPT-4V(ision) System Card},
  author={OpenAI},
  journal={OpenAI Technical Report},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: A Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{li2023blip2,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{chen2024spatialvlm,
  title={SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities},
  author={Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brian and Driess, Danny and Florence, Pete and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  journal={arXiv preprint arXiv:2401.12168},
  year={2024}
}

@article{yang2025embodiedbench,
  title={EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents},
  author={Yang, Rui and Lin, Hanyang and Zhu, Junyu and Huang, Jingyi},
  journal={arXiv preprint arXiv:2502.09560},
  year={2025}
}

@article{thompson2025rem,
  title={REM: A Benchmark for Evaluating Embodied Spatial Reasoning in MLLMs},
  author={Thompson, James and others},
  journal={arXiv preprint arXiv:2512.00736},
  year={2025}
}

% -------------------------------------------------------------------
% SECTION 4: GRAPH NEURAL NETWORKS FOR SPATIAL INTELLIGENCE
% -------------------------------------------------------------------

@article{han2024geometric,
  title={A Survey of Geometric Graph Neural Networks: Data Structures, Models and Applications},
  author={Han, Jiaqi and Cen, Jiacheng and Wu, Liming and Li, Zongzhao and Kong, Xiangzhe and Jiao, Rui and Yu, Ziyang and Xu, Tingyang and Wu, Fandi and Wang, Zihe and others},
  journal={arXiv preprint arXiv:2403.00485},
  year={2024}
}

@article{jin2023stgnn,
  title={Spatio-Temporal Graph Neural Networks for Urban Computing: A Survey},
  author={Jin, Guangyin and Liang, Yuxuan and Fang, Yuchen and Huang, Zezhi and Zhang, Junbo and Zheng, Yu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2023}
}

@article{shehzad2024graphtransformers,
  title={Graph Transformers: A Survey},
  author={Shehzad, Ahsan and Xia, Feng and Abid, Shagufta and Peng, Chao and Yu, Shuo and Zhang, Dongyu and Verspoor, Karin},
  journal={arXiv preprint arXiv:2407.09777},
  year={2024}
}

@inproceedings{li2018dcrnn,
  title={Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting},
  author={Li, Yaguang and Yu, Rose and Shahabi, Cyrus and Liu, Yan},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{yu2018stgcn,
  title={Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting},
  author={Yu, Bing and Yin, Haoteng and Zhu, Zhanxing},
  booktitle={Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence},
  pages={3634--3640},
  year={2018}
}

@inproceedings{wu2019graphwavenet,
  title={Graph WaveNet for Deep Spatial-Temporal Graph Modeling},
  author={Wu, Zonghan and Pan, Shirui and Long, Guodong and Jiang, Jing and Zhang, Chengqi},
  booktitle={Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
  pages={1907--1913},
  year={2019}
}

@article{kipf2017gcn,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2017}
}

@article{velickovic2018gat,
  title={Graph Attention Networks},
  author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2018}
}

@article{hamilton2017graphsage,
  title={Inductive Representation Learning on Large Graphs},
  author={Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{xu2019gin,
  title={How Powerful are Graph Neural Networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2019}
}

% -------------------------------------------------------------------
% SECTION 5: SPATIAL REASONING BENCHMARKS
% -------------------------------------------------------------------

@inproceedings{johnson2017clevr,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2901--2910},
  year={2017}
}

@inproceedings{hudson2019gqa,
  title={GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6700--6709},
  year={2019}
}

@article{suhr2019nlvr2,
  title={A Corpus for Reasoning about Natural Language Grounded in Photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2019}
}

@article{liu2023agentbench,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@article{yao2021alfworld,
  title={ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
  author={Shridhar, Mohit and Yuan, Xingdi and Cote, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  journal={arXiv preprint arXiv:2010.03768},
  year={2021}
}

@article{srivastava2021behavior,
  title={BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments},
  author={Srivastava, Sanjana and Li, Chengshu and Lingelbach, Michael and Martin, Roberto and Xia, Fei and Vainio, Kent and Lian, Zheng and Gokmen, Cem and Buch, Shyamal and Liu, Karen and others},
  journal={arXiv preprint arXiv:2108.03332},
  year={2021}
}

@article{zhou2023webarena,
  title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@article{mineanybuild2025,
  title={MineAnyBuild: A Benchmark for Evaluating Spatial Planning in Minecraft},
  author={Unknown},
  journal={arXiv preprint arXiv:2505.20148},
  year={2025}
}

@article{safeagentbench2025,
  title={SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents},
  author={Unknown},
  journal={arXiv preprint arXiv:2412.13178},
  year={2025}
}

% -------------------------------------------------------------------
% SECTION 6: 3D SCENE UNDERSTANDING
% -------------------------------------------------------------------

@inproceedings{dai2017scannet,
  title={ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Niessner, Matthias},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5828--5839},
  year={2017}
}

@inproceedings{chang2017matterport3d,
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle={2017 International Conference on 3D Vision (3DV)},
  pages={667--676},
  year={2017},
  organization={IEEE}
}

@article{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2020}
}

@article{kerbl20233dgaussian,
  title={3D Gaussian Splatting for Real-Time Radiance Field Rendering},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimkuhler, Thomas and Drettakis, George},
  journal={ACM Transactions on Graphics},
  volume={42},
  number={4},
  pages={1--14},
  year={2023}
}

@article{hong2024llmgrounder,
  title={LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent},
  author={Hong, Jianing and Zheng, Zeren and Zhu, Hao and Xu, Yun and Zhang, Xingyu and Chen, Siheng and Shen, Shenghua},
  journal={arXiv preprint arXiv:2309.12311},
  year={2024}
}

% -------------------------------------------------------------------
% SECTION 7: GEOSPATIAL AI AND REMOTE SENSING
% -------------------------------------------------------------------

@article{jakubik2024prithvi,
  title={Prithvi: A Foundation Model for Earth Observation},
  author={Jakubik, Johannes and Roy, Sujit and Phillips, C E and Fraccaro, Paolo and Godwin, Denys and Zadrozny, Bianca and Szwarcman, Daniela and Gomes, Carlos and Musber, Gabby and Oliveira, Daiki and others},
  journal={arXiv preprint arXiv:2310.18660},
  year={2024}
}

@article{cong2022satmae,
  title={SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery},
  author={Cong, Yezhen and Khanna, Samar and Meng, Chenlin and Liu, Patrick and Rozi, Erik and He, Yutong and Burke, Marshall and Lobell, David and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={197--211},
  year={2022}
}

@article{manas2021seco,
  title={Seasonal Contrast: Unsupervised Pre-Training from Uncurated Remote Sensing Data},
  author={Manas, Oscar and Lacoste, Alexandre and Giro-i-Nieto, Xavier and Vazquez, David and Rodriguez, Pau},
  journal={arXiv preprint arXiv:2103.16607},
  year={2021}
}

@article{sumbul2019bigearthnet,
  title={BigEarthNet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding},
  author={Sumbul, Gencer and Charfuelan, Marcela and Demir, Begum and Markl, Volker},
  journal={arXiv preprint arXiv:1902.06148},
  year={2019}
}

@article{zhang2018siamesecnn,
  title={Change Detection Based on Deep Siamese Convolutional Network for Optical Aerial Images},
  author={Zhang, Chenxiao and Yue, Peng and Tapete, Deodato and Jiang, Liangcun and Shangguan, Boyi and Huang, Lei and Liu, Guangchao},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={14},
  number={10},
  pages={1845--1849},
  year={2018}
}

@article{jean2016poverty,
  title={Combining Satellite Imagery and Machine Learning to Predict Poverty},
  author={Jean, Neal and Burke, Marshall and Xie, Michael and Davis, W Matthew and Lobell, David B and Ermon, Stefano},
  journal={Science},
  volume={353},
  number={6301},
  pages={790--794},
  year={2016}
}

@article{kussul2017crop,
  title={Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data},
  author={Kussul, Nataliia and Lavreniuk, Mykola and Skakun, Sergii and Shelestov, Andrii},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={14},
  number={5},
  pages={778--782},
  year={2017}
}

% -------------------------------------------------------------------
% SECTION 8: WORLD MODELS AND SIMULATION
% -------------------------------------------------------------------

@article{ha2018worldmodels,
  title={World Models},
  author={Ha, David and Schmidhuber, Jurgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@article{yang2024worldmodels,
  title={World Models: A Survey},
  author={Yang, Zhaohan and others},
  journal={arXiv preprint arXiv:2411.14499},
  year={2024}
}

@article{shen2021igibson,
  title={iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks},
  author={Shen, Bokui and Xia, Fei and Li, Chengshu and Martin, Roberto and Fan, Linxi and Wang, Guanzhi and Buch, Shyamal and others},
  journal={arXiv preprint arXiv:2108.03272},
  year={2021}
}

@article{fan2022minedojo,
  title={MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge},
  author={Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18343--18362},
  year={2022}
}

% -------------------------------------------------------------------
% SECTION 9: MULTI-AGENT SYSTEMS
% -------------------------------------------------------------------

@article{wu2023autogen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and others},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@article{li2023camel,
  title={CAMEL: Communicative Agents for Mind Exploration of Large Language Model Society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2303.17760},
  year={2023}
}

@article{hong2023metagpt,
  title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Zhang, Ceyao and Wang, Jinlin and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}

@article{chen2024agentverse,
  title={AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Qian, Chen and Chan, Chi-Min and Qin, Yujia and Lu, Yaxi and Xie, Ruobing and others},
  journal={arXiv preprint arXiv:2308.10848},
  year={2024}
}

% -------------------------------------------------------------------
% SECTION 10: FOUNDATION MODELS AND TRANSFORMERS
% -------------------------------------------------------------------

@article{vaswani2017attention,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2019}
}

@article{brown2020gpt3,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothee and Roziere, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{radford2021clip,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@article{dosovitskiy2021vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2021}
}

% -------------------------------------------------------------------
% SECTION 11: REINFORCEMENT LEARNING FOR AGENTS
% -------------------------------------------------------------------

@article{schulman2017ppo,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{haarnoja2018sac,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{ouyang2022instructgpt,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{christiano2017rlhf,
  title={Deep Reinforcement Learning from Human Preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

% -------------------------------------------------------------------
% SECTION 12: SAFETY AND ALIGNMENT
% -------------------------------------------------------------------

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{amodei2016safety,
  title={Concrete Problems in AI Safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mane, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{hendrycks2021unsolved,
  title={Unsolved Problems in ML Safety},
  author={Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2109.13916},
  year={2021}
}

% -------------------------------------------------------------------
% SECTION 13: ADDITIONAL SPATIAL REASONING WORKS
% -------------------------------------------------------------------

@article{zhang2023graph,
  title={Graph-Based Planning for Embodied Agents},
  author={Zhang, Yiwen and others},
  journal={arXiv preprint},
  year={2023}
}

@article{song2023llmplanner,
  title={LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  journal={arXiv preprint arXiv:2212.04088},
  year={2023}
}

@article{hao2023rap,
  title={Reasoning with Language Model is Planning with World Model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{krantz2020waypoint,
  title={Waypoint Models for Instruction-guided Navigation in Continuous Environments},
  author={Krantz, Jacob and Wijmans, Erik and Majumdar, Arjun and Batra, Dhruv and Lee, Stefan},
  journal={arXiv preprint arXiv:2110.02207},
  year={2020}
}

@article{zhu2019vision,
  title={Vision-Language Navigation with Self-Supervised Auxiliary Reasoning Tasks},
  author={Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  journal={arXiv preprint arXiv:1911.07883},
  year={2019}
}

@article{das2018eqa,
  title={Embodied Question Answering},
  author={Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  journal={arXiv preprint arXiv:1711.11543},
  year={2018}
}

@article{yang2020spatialsense,
  title={SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition},
  author={Yang, Kaiyu and Russakovsky, Olga and Deng, Jia},
  journal={arXiv preprint arXiv:1908.02660},
  year={2020}
}

@article{zheng2014urban,
  title={Urban Computing: Concepts, Methodologies, and Applications},
  author={Zheng, Yu and Capra, Licia and Wolfson, Ouri and Yang, Hai},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={5},
  number={3},
  pages={1--55},
  year={2014}
}

@article{jiang2022gnn,
  title={Graph Neural Networks for Traffic Forecasting: A Survey},
  author={Jiang, Weiwei and Luo, Jiayun},
  journal={arXiv preprint arXiv:2101.11174},
  year={2022}
}

% -------------------------------------------------------------------
% SECTION 14: VLA MODELS AND ROBOTICS
% -------------------------------------------------------------------

@article{brohan2023rt2,
  title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{padalkar2023rtx,
  title={Open X-Embodiment: Robotic Learning Datasets and RT-X Models},
  author={Padalkar, Abhishek and Poolber, Acorn and Bewley, Alex and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@article{zitkovich2023rt1,
  title={RT-1: Robotics Transformer for Real-World Control at Scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gober, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2023}
}

% -------------------------------------------------------------------
% SECTION 15: ADDITIONAL BENCHMARKS AND DATASETS
% -------------------------------------------------------------------

@article{deitke2022procthor,
  title={ProcTHOR: Large-Scale Embodied AI Using Procedural Generation},
  author={Deitke, Matt and VanderBilt, Eli and Herrasti, Alvaro and Weihs, Luca and Salvador, Jordi and Ehsani, Kiana and Han, Winson and Kolve, Eric and Farhadi, Ali and Kembhavi, Aniruddha and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5982--5994},
  year={2022}
}

@article{puig2018virtualhome,
  title={VirtualHome: Simulating Household Activities via Programs},
  author={Puig, Xavier and Ra, Kevin and Boben, Marko and Li, Jiaman and Wang, Tingwu and Fidler, Sanja and Torralba, Antonio},
  journal={arXiv preprint arXiv:1806.07011},
  year={2018}
}

@article{kolve2017ai2thor,
  title={AI2-THOR: An Interactive 3D Environment for Visual AI},
  author={Kolve, Eric and Mottaghi, Roozbeh and Han, Winson and VanderBilt, Eli and Weihs, Luca and Herrasti, Alvaro and Gordon, Daniel and Zhu, Yuke and Gupta, Abhinav and Farhadi, Ali},
  journal={arXiv preprint arXiv:1712.05474},
  year={2017}
}

@article{xia2018gibson,
  title={Gibson Env: Real-World Perception for Embodied Agents},
  author={Xia, Fei and Zamir, Amir R and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
  journal={arXiv preprint arXiv:1808.10654},
  year={2018}
}

@article{shridhar2020alfred,
  title={ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  journal={arXiv preprint arXiv:1912.01734},
  year={2020}
}

@article{jimenez2024swebench,
  title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2024}
}

@article{deng2024mind2web,
  title={Mind2Web: Towards a Generalist Agent for the Web},
  author={Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Sam and Wang, Boshi and Sun, Huan and Su, Yu},
  journal={arXiv preprint arXiv:2306.06070},
  year={2024}
}

% -------------------------------------------------------------------
% SECTION 16: SPATIAL REASONING IN MLLMS
% -------------------------------------------------------------------

@article{chen2024spatialreasoning,
  title={Spatial Reasoning in Multimodal Large Language Models: A Survey},
  author={Chen, Zhaohan and others},
  journal={arXiv preprint arXiv:2511.15722},
  year={2024}
}

@article{kamath2023whatsleft,
  title={What's Left? Concept Grounding with Logic-Enhanced Foundation Models},
  author={Kamath, Aishwarya and Hessel, Jack and Chang, Kai-Wei},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{liu2023visualspatial,
  title={Visual Spatial Reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023}
}

% -------------------------------------------------------------------
% SECTION 17: CODE AGENTS AND SOFTWARE ENGINEERING
% -------------------------------------------------------------------

@article{yang2024sweagent,
  title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Liber, Kilian and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

@article{qian2024chatdev,
  title={ChatDev: Communicative Agents for Software Development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2024}
}

% -------------------------------------------------------------------
% SECTION 18: ADDITIONAL REFERENCES
% -------------------------------------------------------------------

@article{shen2024hugginggpt,
  title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2303.17580},
  year={2024}
}

@article{nakano2021webgpt,
  title={WebGPT: Browser-assisted Question-answering with Human Feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{significant2023autogpt,
  title={Auto-GPT: An Autonomous GPT-4 Experiment},
  author={Significant Gravitas},
  journal={GitHub repository},
  year={2023}
}

@article{chase2022langchain,
  title={LangChain},
  author={Chase, Harrison},
  journal={GitHub repository},
  year={2022}
}

@article{yao2023retroformer,
  title={Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization},
  author={Yao, Weiran and Heinecke, Shelby and Niebles, Juan Carlos and Liu, Zhiwei and Feng, Yue and Xue, Le and Murber, Rithesh and Chen, Zeyuan and Zhang, Jianguo and Arber, Devansh and others},
  journal={arXiv preprint arXiv:2308.02151},
  year={2023}
}

@article{madaan2023selfrefine,
  title={Self-Refine: Iterative Refinement with Self-Feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{huang2022zeroshot,
  title={Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  journal={arXiv preprint arXiv:2201.07207},
  year={2022}
}

@article{huang2022inner,
  title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}
