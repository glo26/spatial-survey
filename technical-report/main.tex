\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{array}
\usepackage{tcolorbox}
\usepackage{float}

% Define colors
\definecolor{atlasblue}{RGB}{0, 82, 147}
\definecolor{keybox}{RGB}{230, 242, 255}

% Key Takeaways box
\newtcolorbox{keytakeaways}[1][]{
  colback=keybox,
  colframe=atlasblue,
  fonttitle=\bfseries,
  title=#1,
  boxrule=0.5pt,
  arc=2pt
}

\begin{document}

% Title Page
\begin{center}
\rule{\textwidth}{1.5pt}
\vspace{0.5cm}

{\Huge \bf Spatial Intelligence at Scale}

\vspace{0.3cm}

{\LARGE AtlasPro AI's Approach to Building\\Agentic Geospatial Systems}

\vspace{0.5cm}
\rule{\textwidth}{0.5pt}
\vspace{1cm}

{\large \textbf{Technical Report}}

\vspace{0.5cm}

{\large Version 1.0 \quad|\quad January 2026}

\vspace{1.5cm}

\begin{tabular}{ccc}
\textbf{Gloria Felicia} & \textbf{Nolan Bryant} & \textbf{Handi Putra} \\
\small{Research Lead} & \small{Systems Architect} & \small{ML Engineer} \\
\end{tabular}

\vspace{0.5cm}

\begin{tabular}{ccc}
\textbf{Ayaan Gazali} & \textbf{Eliel Lobo} & \textbf{Esteban Rojas} \\
\small{Research Engineer} & \small{Research Engineer} & \small{Research Engineer} \\
\end{tabular}

\vspace{1.5cm}

{\Large \textbf{AtlasPro AI}}

\vspace{0.3cm}

{\large Research Division}

\vspace{2cm}

\textit{Correspondence: research@atlaspro.ai}

\end{center}

\newpage

% Abstract
\section*{Abstract}

This technical report presents AtlasPro AI's research approach to building autonomous spatial intelligence systems. We introduce a unified three-axis taxonomy that organizes the intersection of agentic AI capabilities with spatial task domains across multiple scales. Our preliminary research, synthesizing over 800 papers from top venues, reveals critical gaps in existing approaches: current systems excel within narrow operational envelopes but fail systematically when tasks require cross-scale reasoning or long-horizon planning under geometric constraints.

We identify four key findings that inform our architectural approach: (1) memory systems must be explicitly spatial, encoding not just what happened but where; (2) planning under geometric constraints requires hybrid symbolic-neural representations; (3) graph neural networks provide the structural inductive bias necessary for spatial reasoning that transformers alone cannot capture; and (4) world models offer a path to safe deployment by enabling planning through imagination rather than trial-and-error in the physical world.

This report documents our research methodology, presents the three-axis taxonomy as a framework for system design, analyzes failure modes across 12 representative methods, and outlines AtlasPro AI's architectural principles for building spatially-aware autonomous agents. We release this report to establish priority on our methodological contributions and to invite collaboration from the research community.

\vspace{0.5cm}

\noindent\textbf{Keywords:} Spatial Intelligence, Agentic AI, World Models, Graph Neural Networks, Embodied AI, Geospatial AI, Vision-Language-Action Models

\tableofcontents
\newpage

% Section 1: Introduction
\section{Introduction}

Large language models have achieved remarkable success in symbolic reasoning, code generation, and natural language understanding. Yet these same models fail systematically when confronted with the physical world. Navigation agents hallucinate paths through walls. Manipulation planners propose grasps that violate basic physics. Embodied systems misjudge distances by orders of magnitude. The gap between linguistic competence and spatial competence represents one of the most significant barriers to deploying AI systems in real-world applications.

AtlasPro AI was founded to bridge this gap. Our research program investigates how to build autonomous systems that can perceive three-dimensional structure, reason about object relationships under physical constraints, and execute actions that respect the geometry of the world. This is not merely an incremental improvement over language understanding; it requires fundamentally different representations, architectures, and training paradigms.

This technical report documents our research approach. We present findings from a systematic analysis of over 800 papers spanning agentic AI, embodied AI, graph neural networks, world models, and geospatial foundation models. From this analysis, we derive a unified taxonomy and identify the architectural principles that will guide our system development.

\subsection{Scope and Limitations of This Report}

This report presents AtlasPro AI's research methodology and preliminary findings. It does not describe a deployed system or report experimental results from a novel architecture. Our contributions are:

\begin{enumerate}
    \item A \textbf{three-axis taxonomy} (Task $\times$ Capability $\times$ Scale) that organizes the design space for spatial AI agents
    \item A \textbf{systematic analysis} of failure modes across representative methods
    \item \textbf{Architectural principles} derived from our literature synthesis
    \item A \textbf{research roadmap} for AtlasPro AI's development program
\end{enumerate}

We are transparent about what this report is not: it is not a peer-reviewed publication, it does not contain novel experimental results, and it does not describe production-ready systems. We release it to establish priority on our methodological contributions and to invite feedback from the research community.

\subsection{Why Spatial Intelligence Matters Now}

Three converging trends make spatial intelligence tractable and urgent:

\textbf{Foundation Model Capabilities.} Large language models now exhibit emergent reasoning capabilities \citep{wei2022emergent, brown2020language}. Vision-language models can understand complex scenes \citep{liu2023llava, alayrac2022flamingo}. The question is no longer whether AI can reason, but whether it can reason about the physical world.

\textbf{Robotics at Scale.} Open-source robotics datasets \citep{open_x_embodiment_rt_x_2023, walke2023bridgedata} and foundation models \citep{team2024octo, kim2024openvla} have democratized embodied AI research. The barrier to entry has dropped dramatically.

\textbf{Industry Demand.} Autonomous vehicles, warehouse robotics, drone delivery, and smart city infrastructure all require spatial intelligence. The market opportunity exceeds \$100 billion by 2030 \citep{mckinsey2023robotics}.

AtlasPro AI is positioned at this intersection. Our research program aims to develop the foundational capabilities for spatially-aware autonomous systems.

\section{Research Methodology}

Our findings derive from a systematic literature review conducted between September 2025 and January 2026.

\subsection{Paper Selection}

We applied a multi-stage filtering process:

\textbf{Stage 1: Temporal Filter.} We focused on papers published between 2020 and 2025, with selective inclusion of foundational works from earlier years.

\textbf{Stage 2: Venue Filter.} We prioritized top-tier venues: NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, CoRL, RSS, ICRA, and high-impact arXiv preprints with significant citations.

\textbf{Stage 3: Relevance Filter.} Papers were included if they addressed at least one of: agentic AI architectures, spatial reasoning, embodied AI, graph neural networks for spatial data, world models, or geospatial foundation models.

\textbf{Stage 4: Quality Filter.} Two researchers independently assessed each paper. Inter-annotator agreement was 94\%. Disagreements were resolved through discussion.

\subsection{Analysis Framework}

For each included paper, we extracted:
\begin{itemize}
    \item Primary spatial task (navigation, scene understanding, manipulation, geospatial)
    \item Agentic capabilities employed (memory, planning, tool use)
    \item Spatial scale of operation (micro, meso, macro)
    \item Representation type (symbolic, metric, latent, multimodal)
    \item Reported failure modes and limitations
\end{itemize}

This structured extraction enabled the taxonomy development and failure mode analysis presented in subsequent sections.

\section{The Three-Axis Taxonomy}

We propose a unified taxonomy that organizes the intersection of agentic AI and spatial intelligence. The taxonomy comprises three orthogonal axes: Spatial Task, Agentic Capability, and Spatial Scale.

\subsection{Axis 1: Spatial Task}

We identify four primary spatial task domains:

\textbf{Navigation.} Moving through environments toward goals. This includes vision-language navigation \citep{anderson2018vln}, object-goal navigation \citep{batra2020objectnav}, and point-goal navigation. The core challenge is grounding linguistic instructions in traversable paths.

\textbf{Scene Understanding.} Perceiving and representing 3D structure. This encompasses depth estimation, semantic segmentation, 3D reconstruction \citep{mildenhall2020nerf, kerbl20233dgaussian}, and scene graph construction \citep{armeni2019scene}. The core challenge is building representations that support downstream reasoning.

\textbf{Manipulation.} Interacting with objects through physical contact. This includes grasping \citep{mahler2017dexnet}, pick-and-place \citep{zeng2021transporter}, and long-horizon task completion \citep{shridhar2022cliport}. The core challenge is planning contact-rich interactions under uncertainty.

\textbf{Geospatial Analysis.} Reasoning about large-scale spatial phenomena. This includes remote sensing \citep{jakubik2024prithvi}, traffic prediction \citep{li2018dcrnn}, and urban computing \citep{zheng2014urban}. The core challenge is handling heterogeneous data sources at city-to-global scales.

\subsection{Axis 2: Agentic Capability}

We identify three core agentic capabilities:

\textbf{Memory Systems.} How agents accumulate and retrieve spatial knowledge. This includes cognitive maps \citep{tolman1948cognitive, chaplot2020neural}, semantic maps \citep{huang2023vlmaps}, scene graphs \citep{rosinol2020scene}, and retrieval-augmented generation \citep{lewis2020rag}. The central question is: \textit{How can agents maintain persistent spatial knowledge across varying time horizons?}

\textbf{Planning Systems.} How agents decompose goals into executable action sequences. This includes task planning \citep{garrett2021tamp}, motion planning \citep{lavalle2006planning}, hierarchical planning \citep{nachum2018hiro}, and LLM-based planning \citep{huang2022language}. The central question is: \textit{How can agents plan under geometric constraints while accounting for uncertainty?}

\textbf{Tool Use and Action.} How agents translate decisions into physical effects. This includes API integration \citep{schick2023toolformer}, code generation \citep{liang2023code}, and vision-language-action models \citep{brohan2023rt2, kim2024openvla}. The central question is: \textit{How can language-based reasoning be grounded in precise geometric actions?}

\subsection{Axis 3: Spatial Scale}

We distinguish three spatial scales with distinct computational and representational requirements:

\textbf{Micro-spatial ($<$1m).} Fine manipulation, grasping, and precise positioning. Requires millimeter-level accuracy. Representations must capture detailed geometry and contact dynamics.

\textbf{Meso-spatial (1m--100m).} Room-scale navigation, indoor exploration, and local scene understanding. Requires meter-level accuracy. Representations must balance detail with coverage.

\textbf{Macro-spatial ($>$100m).} City-scale planning, satellite imagery analysis, and infrastructure networks. Requires kilometer-level reasoning. Representations must handle sparse observations over large areas.

\begin{keytakeaways}[Key Insight: Scale Determines Architecture]
Methods optimized for one scale often fail at others. Micro-scale manipulation systems achieve precision but lack macro-scale planning. Geospatial models handle city-scale reasoning but cannot guide fine manipulation. A unified spatial AI system must bridge these scales, which remains an open challenge.
\end{keytakeaways}

\subsection{Taxonomy Mapping}

Table \ref{tab:taxonomy} maps representative methods to our taxonomy, demonstrating how the framework organizes the field.

\begin{table}[h!]
\centering
\caption{Representative Methods Mapped to the Three-Axis Taxonomy}
\label{tab:taxonomy}
\small
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Method} & \textbf{Spatial Task} & \textbf{Agentic Capability} & \textbf{Scale} & \textbf{Primary Failure Mode} \\
\midrule
VLN-BERT & Navigation & Memory + Planning & Meso & Instruction grounding \\
SayCan & Manipulation & Planning + Tool Use & Micro-Meso & Affordance mismatch \\
RT-2 & Manipulation & Tool Use & Micro & Out-of-distribution \\
VLMaps & Navigation & Memory & Meso & Semantic drift \\
Voyager & Navigation + Manip. & Memory + Planning & Meso & Code execution \\
DCRNN & Geospatial & Memory (low planning) & Macro & Non-stationarity \\
Graph WaveNet & Geospatial & Memory (low planning) & Macro & Sparse regions \\
Prithvi & Geospatial & Memory only & Macro & No action capability \\
DreamerV3 & Navigation + Manip. & Planning (World Model) & Micro-Meso & Model compounding \\
PaLM-E & Manipulation & Planning + Tool Use & Micro-Meso & Hallucination \\
OpenVLA & Manipulation & Tool Use & Micro & Limited generalization \\
LLaGA & Scene Understanding & Memory & Meso & Graph construction \\
\bottomrule
\end{tabular}
\end{table}

\section{Preliminary Findings: Failure Mode Analysis}

Our literature synthesis reveals systematic failure patterns that inform AtlasPro AI's architectural decisions.

\subsection{Spatial Hallucination}

Language models describe spatial configurations that do not exist. GPT-4V fails on 40\% of spatial relationship questions in SpatialBench \citep{chen2024spatialvlm}. The model confidently describes objects as ``to the left of'' when they are actually ``behind,'' or claims paths exist through solid walls.

\textbf{Root Cause.} Language models learn spatial language from text, not from grounded experience. The word ``left'' appears in training data without consistent geometric grounding.

\textbf{Implication for AtlasPro.} Spatial representations must be grounded in metric observations, not derived solely from language.

\subsection{Reference Frame Confusion}

Agents conflate egocentric (body-relative) and allocentric (world-relative) coordinate systems. Vision-language navigation agents show 15--20\% error rates from frame misalignment \citep{anderson2018vln}.

\textbf{Root Cause.} Natural language instructions often leave reference frames implicit. ``Turn left'' is egocentric; ``go to the kitchen'' is allocentric. Agents must infer the intended frame from context.

\textbf{Implication for AtlasPro.} Systems must explicitly represent and transform between reference frames.

\subsection{Scale Insensitivity}

Models trained at one scale fail at others. SayCan's affordance model, trained on tabletop manipulation, fails when applied to room-scale tasks \citep{ahn2022saycan}. The model cannot distinguish between ``reachable'' at arm's length versus ``reachable'' after navigation.

\textbf{Root Cause.} Scale is often implicit in training data. Models learn correlations that hold at one scale but not others.

\textbf{Implication for AtlasPro.} Architectures must explicitly encode scale and support cross-scale reasoning.

\subsection{Temporal Drift}

Spatial memory degrades over extended operation. VLMaps shows semantic drift after 100+ steps without map updates \citep{huang2023vlmaps}. Accumulated localization error corrupts the spatial representation.

\textbf{Root Cause.} Spatial representations are updated incrementally. Small errors compound over time without correction mechanisms.

\textbf{Implication for AtlasPro.} Memory systems must include mechanisms for uncertainty estimation and correction.

\subsection{Planning Constraint Violations}

LLM-based planners propose actions that violate geometric constraints. On BEHAVIOR-1K, LLM planners achieve only 12\% success due to collision-ignoring plans \citep{li2023behavior}. The planner proposes ``move the chair'' without checking if the path is clear.

\textbf{Root Cause.} LLMs plan in language space, which does not enforce geometric consistency. The word ``move'' does not carry collision information.

\textbf{Implication for AtlasPro.} Planning must integrate geometric reasoning, not just linguistic sequencing.

\subsection{Long-Horizon Credit Assignment}

Performance degrades as task horizons extend. On ALFRED, success drops from 65\% to 18\% as task steps increase from 5 to 20 \citep{shridhar2020alfred}. Agents cannot determine which early decisions caused late failures.

\textbf{Root Cause.} Reward signals are sparse and delayed. The agent receives feedback only at task completion, making it difficult to learn from intermediate mistakes.

\textbf{Implication for AtlasPro.} Systems need hierarchical decomposition and intermediate feedback mechanisms.

\begin{keytakeaways}[Key Insight: Failure Modes Are Architectural]
These failures are not random errors but systematic consequences of architectural choices. Addressing them requires fundamental changes to how spatial AI systems are designed, not just better training data or larger models.
\end{keytakeaways}

\section{AtlasPro AI's Architectural Principles}

Based on our analysis, we derive six architectural principles that will guide AtlasPro AI's system development.

\subsection{Principle 1: Explicit Spatial Memory}

Memory systems must encode \textit{where}, not just \textit{what}. This means:

\begin{itemize}
    \item Cognitive maps that maintain metric relationships between locations
    \item Scene graphs that encode spatial relationships between objects
    \item Episodic memory that indexes experiences by location
    \item Uncertainty estimates that degrade gracefully over time
\end{itemize}

We draw inspiration from VLMaps \citep{huang2023vlmaps}, Neural SLAM \citep{chaplot2020neural}, and 3D scene graphs \citep{rosinol2020scene}, while addressing their limitations around temporal drift and scale.

\subsection{Principle 2: Hybrid Planning Under Constraints}

Planning must integrate symbolic task decomposition with geometric feasibility checking. This means:

\begin{itemize}
    \item Task-and-motion planning (TAMP) integration \citep{garrett2021tamp}
    \item Geometric constraint propagation during plan generation
    \item Continuous replanning as the world state changes
    \item Hierarchical abstraction to manage complexity
\end{itemize}

Pure LLM-based planning fails because language does not enforce geometric consistency. Pure motion planning fails because it cannot handle abstract goals. The hybrid approach combines their strengths.

\subsection{Principle 3: Graph-Structured Representations}

Graphs provide the inductive bias necessary for spatial reasoning. This means:

\begin{itemize}
    \item Scene graphs for object relationships
    \item Road networks for navigation
    \item Spatial knowledge graphs for semantic reasoning
    \item GNN-LLM integration for combining structural and semantic understanding
\end{itemize}

Transformers treat all tokens uniformly; they do not inherently respect spatial adjacency. Graph neural networks encode relational structure directly, making them better suited for spatial reasoning \citep{kipf2017gcn, velickovic2018gat}.

\subsection{Principle 4: World Models for Safe Planning}

Learning predictive models enables planning through imagination rather than trial-and-error. This means:

\begin{itemize}
    \item Latent dynamics models that predict future states \citep{hafner2023dreamerv3}
    \item Video prediction for visual planning \citep{hu2023gaia1}
    \item Uncertainty-aware predictions for safe exploration
    \item Sim-to-real transfer for deployment
\end{itemize}

World models allow agents to ``imagine'' the consequences of actions before executing them. This is critical for safety-critical applications where trial-and-error is unacceptable.

\subsection{Principle 5: Multi-Scale Architecture}

Systems must explicitly handle multiple spatial scales. This means:

\begin{itemize}
    \item Scale-aware representations that encode resolution explicitly
    \item Hierarchical processing from fine to coarse
    \item Cross-scale attention mechanisms
    \item Scale-conditioned action generation
\end{itemize}

A manipulation action at micro-scale may require navigation planning at meso-scale and route optimization at macro-scale. The architecture must support this seamlessly.

\subsection{Principle 6: Grounded Action Generation}

Language must be grounded in precise geometric actions. This means:

\begin{itemize}
    \item Vision-language-action models that output continuous controls \citep{brohan2023rt2}
    \item Affordance prediction to filter infeasible actions \citep{ahn2022saycan}
    \item Code generation for programmatic control \citep{liang2023code}
    \item Closed-loop execution with visual feedback
\end{itemize}

The gap between ``pick up the cup'' and the motor commands to actually grasp it is vast. Bridging this gap requires models that understand both language and geometry.

\section{Technical Deep-Dive: Core Components}

This section provides technical detail on the components central to AtlasPro AI's approach.

\subsection{Memory Architecture}

We propose a three-tier memory architecture:

\textbf{Tier 1: Working Memory.} Operates within the LLM context window. Stores current observations, recent actions, and active goals. Capacity: 8K--128K tokens depending on model.

\textbf{Tier 2: Spatial Memory.} Persistent storage of spatial knowledge. Implemented as a combination of:
\begin{itemize}
    \item Vector database for semantic retrieval (e.g., embeddings of location descriptions)
    \item Metric map for geometric relationships (e.g., occupancy grid, point cloud)
    \item Scene graph for object relationships (e.g., ``cup is on table'')
\end{itemize}

\textbf{Tier 3: Episodic Memory.} Long-term storage of experiences indexed by location and time. Enables learning from past successes and failures.

The key innovation is the integration layer that queries all three tiers based on the current context and retrieves relevant information for the LLM.

\subsection{GNN-LLM Integration}

We identify three integration patterns:

\textbf{Pattern A: GNN as Encoder.} The GNN encodes graph structure into embeddings that are projected into the LLM's token space. The LLM then reasons over the combined text and graph information.

\textbf{Pattern B: LLM as Graph Enhancer.} The LLM generates node features, edge labels, or graph augmentations that improve GNN performance.

\textbf{Pattern C: Iterative Refinement.} The GNN and LLM alternate, with each refining the other's outputs.

Our preliminary analysis suggests Pattern A is most suitable for spatial reasoning tasks, where the graph structure (e.g., scene graph, road network) provides critical inductive bias that the LLM alone cannot capture.

\subsection{World Model Architecture}

We adopt the Dreamer family architecture \citep{hafner2019dream, hafner2021dreamerv2, hafner2023dreamerv3} as our starting point:

\textbf{Encoder.} Maps observations to latent states: $z_t = \text{enc}(o_t)$

\textbf{Dynamics Model.} Predicts future latent states: $\hat{z}_{t+1} = \text{dyn}(z_t, a_t)$

\textbf{Reward Predictor.} Estimates rewards from latent states: $\hat{r}_t = \text{rew}(z_t)$

\textbf{Decoder.} Reconstructs observations for training: $\hat{o}_t = \text{dec}(z_t)$

The key advantage is that planning occurs entirely in latent space, enabling fast rollouts without expensive simulation.

\subsection{Vision-Language-Action Models}

For grounded action generation, we build on the RT-2 \citep{brohan2023rt2} and OpenVLA \citep{kim2024openvla} architectures:

\textbf{Input.} Image observation $I$ and language instruction $L$

\textbf{Processing.} Vision encoder extracts features; language model processes instruction; cross-attention fuses modalities

\textbf{Output.} Action tokens decoded to continuous robot commands

The critical design choice is action representation. Discretizing the action space enables language model training but sacrifices precision. Continuous outputs preserve precision but require architectural modifications.

\section{Benchmark Analysis}

We analyze key benchmarks to identify evaluation gaps and inform AtlasPro AI's internal benchmarking strategy.

\subsection{Navigation Benchmarks}

\begin{table}[h!]
\centering
\caption{Navigation Benchmark Comparison}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Benchmark} & \textbf{Environment} & \textbf{Instruction Type} & \textbf{Key Metric} \\
\midrule
R2R \citep{anderson2018vln} & Matterport3D & Step-by-step & SPL \\
RxR \citep{ku2020room} & Matterport3D & Detailed, multilingual & nDTW \\
REVERIE \citep{qi2020reverie} & Matterport3D & High-level + object & SR \\
SOON \citep{zhu2021soon} & Matterport3D & Object-centric & SR \\
Habitat ObjectNav & Habitat & Object category & SPL \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Gap Identified.} Existing benchmarks focus on single-episode navigation. They do not evaluate persistent spatial memory across multiple episodes or long-horizon exploration.

\subsection{Manipulation Benchmarks}

\begin{table}[h!]
\centering
\caption{Manipulation Benchmark Comparison}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Benchmark} & \textbf{Tasks} & \textbf{Horizon} & \textbf{Key Challenge} \\
\midrule
RLBench \citep{james2020rlbench} & 100 & Short & Diversity \\
Meta-World \citep{yu2020metaworld} & 50 & Short & Multi-task \\
CALVIN \citep{mees2022calvin} & 34 & Long & Language grounding \\
ALFRED \citep{shridhar2020alfred} & 25K & Long & Embodied instruction \\
BEHAVIOR-1K \citep{li2023behavior} & 1000 & Long & Realistic activities \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Gap Identified.} Benchmarks evaluate task success but not failure mode diagnosis. Understanding \textit{why} agents fail is as important as measuring \textit{how often}.

\subsection{Agent Benchmarks}

\begin{table}[h!]
\centering
\caption{Agent Benchmark Comparison}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Benchmark} & \textbf{Environments} & \textbf{Focus} & \textbf{Spatial?} \\
\midrule
AgentBench \citep{liu2023agentbench} & 8 & General LLM agents & Limited \\
WebArena \citep{zhou2024webarena} & Web & Web navigation & No \\
OSWorld \citep{xie2024osworld} & Desktop & OS interaction & No \\
EmbodiedBench \citep{yang2025embodiedbench} & Simulation & Embodied MLLM & Yes \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Gap Identified.} No benchmark comprehensively evaluates spatial reasoning across scales. EmbodiedBench is closest but focuses on meso-scale embodied tasks.

\begin{keytakeaways}[Key Insight: Benchmark Gaps]
The field lacks benchmarks that evaluate: (1) cross-scale spatial reasoning, (2) persistent spatial memory, (3) failure mode diagnosis, and (4) safe exploration. AtlasPro AI's internal benchmarking will address these gaps.
\end{keytakeaways}

\section{Industry Landscape}

We analyze industry leaders to identify design patterns and market positioning.

\subsection{Autonomous Vehicles}

\textbf{Waymo} has deployed the most mature autonomous driving system, with millions of miles of real-world operation. Their recent EMMA model \citep{waymo_emma_2024} demonstrates end-to-end multimodal driving. Key lesson: safety requires extensive real-world validation, not just simulation.

\textbf{Tesla} pursues a vision-only approach, betting that camera-based perception can match or exceed lidar. Key lesson: data scale can compensate for sensor limitations.

\textbf{Cruise and Zoox} focus on urban robotaxi deployment. Key lesson: constrained operational domains enable faster deployment.

\subsection{Robotics}

\textbf{Boston Dynamics} demonstrates state-of-the-art locomotion and manipulation. Key lesson: hardware and control co-design matters as much as perception.

\textbf{Figure AI and 1X} are developing humanoid robots for general-purpose tasks. Key lesson: the market is betting on generalist robots over specialized solutions.

\textbf{Covariant} applies foundation models to warehouse robotics. Key lesson: industrial applications provide data and revenue to fund research.

\subsection{Geospatial Intelligence}

\textbf{Palantir} provides data integration and analysis for defense and enterprise. Key lesson: the value is in integration, not just algorithms.

\textbf{ESRI} dominates enterprise GIS with ArcGIS. Key lesson: ecosystem lock-in creates durable competitive advantage.

\textbf{Planet Labs} operates the largest constellation of Earth-imaging satellites. Key lesson: data access is a moat.

\subsection{Positioning for AtlasPro AI}

Based on this analysis, AtlasPro AI will focus on:

\begin{enumerate}
    \item \textbf{Cross-scale reasoning} that existing players do not address
    \item \textbf{GNN-LLM integration} as a differentiating technical capability
    \item \textbf{Safety-first development} using world models for planning
    \item \textbf{Open research} to build community and attract talent
\end{enumerate}

\section{Research Roadmap}

AtlasPro AI's research program proceeds in three phases.

\subsection{Phase 1: Foundation (Q1--Q2 2026)}

\textbf{Objective.} Establish core infrastructure and validate architectural principles.

\textbf{Deliverables.}
\begin{itemize}
    \item Internal benchmarking framework covering navigation, manipulation, and geospatial tasks
    \item Prototype memory architecture with three-tier integration
    \item GNN-LLM integration baseline on scene graph reasoning
    \item Simulation environment setup (Habitat, Isaac Sim)
\end{itemize}

\subsection{Phase 2: Integration (Q3--Q4 2026)}

\textbf{Objective.} Integrate components into unified system and evaluate on benchmarks.

\textbf{Deliverables.}
\begin{itemize}
    \item Unified spatial agent architecture
    \item World model integration for safe planning
    \item Cross-scale reasoning demonstration
    \item Internal benchmark results and analysis
\end{itemize}

\subsection{Phase 3: Deployment (2027)}

\textbf{Objective.} Transfer to real-world applications and establish production capabilities.

\textbf{Deliverables.}
\begin{itemize}
    \item Sim-to-real transfer validation
    \item Pilot deployments in target applications
    \item Safety certification process
    \item Production infrastructure
\end{itemize}

\section{Limitations and Risks}

We acknowledge the following limitations of our current work and risks to our research program.

\subsection{Limitations of This Report}

\begin{itemize}
    \item \textbf{No experimental validation.} The architectural principles are derived from literature analysis, not from experiments on our own systems.
    \item \textbf{Selection bias.} Our paper selection may have missed relevant work outside our search scope.
    \item \textbf{Rapidly evolving field.} Findings may be outdated as the field advances.
\end{itemize}

\subsection{Research Risks}

\begin{itemize}
    \item \textbf{Integration complexity.} Combining memory, planning, GNNs, and world models is technically challenging. Integration may prove harder than anticipated.
    \item \textbf{Sim-to-real gap.} Performance in simulation may not transfer to real-world deployment.
    \item \textbf{Compute requirements.} Training world models and large VLAs requires significant computational resources.
    \item \textbf{Safety challenges.} Deploying autonomous systems in the physical world carries inherent risks.
\end{itemize}

\subsection{Mitigation Strategies}

\begin{itemize}
    \item Incremental development with frequent evaluation checkpoints
    \item Collaboration with academic partners for validation
    \item Conservative deployment strategy with extensive testing
    \item Safety engineering practices including red teaming and formal verification where applicable
\end{itemize}

\section{Conclusion}

This technical report has presented AtlasPro AI's research approach to building autonomous spatial intelligence systems. Our key contributions are:

\begin{enumerate}
    \item A \textbf{three-axis taxonomy} (Task $\times$ Capability $\times$ Scale) that organizes the design space for spatial AI
    \item A \textbf{systematic failure mode analysis} revealing architectural limitations of current approaches
    \item \textbf{Six architectural principles} that will guide our system development
    \item A \textbf{research roadmap} for AtlasPro AI's development program
\end{enumerate}

We release this report to establish priority on our methodological contributions, to invite feedback from the research community, and to signal our commitment to open research. Spatial intelligence represents one of the most important frontiers in AI, and we believe progress requires collaboration across academia and industry.

\vspace{0.5cm}

\noindent\textbf{Acknowledgments.} We thank the broader research community whose work made this analysis possible. This report synthesizes insights from hundreds of researchers; any errors in interpretation are our own.

\vspace{0.5cm}

\noindent\textbf{Contact.} Questions and feedback: research@atlaspro.ai

\vspace{0.5cm}

\noindent\textbf{Version History.}
\begin{itemize}
    \item v1.0 (January 2026): Initial release
\end{itemize}

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
